{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autoform 0.1.0 requires langchain-core<0.3.0,>=0.2.1, but you have langchain-core 0.3.5 which is incompatible.\n",
      "autoform 0.1.0 requires pydantic==2.6.4, but you have pydantic 2.9.2 which is incompatible.\n",
      "chromadb 0.4.7 requires fastapi<0.100.0,>=0.95.2, but you have fastapi 0.110.1 which is incompatible.\n",
      "chromadb 0.4.7 requires pydantic<2.0,>=1.9, but you have pydantic 2.9.2 which is incompatible.\n",
      "instructor 0.6.2 requires docstring-parser<0.16,>=0.15, but you have docstring-parser 0.16 which is incompatible.\n",
      "instructor 0.6.2 requires typer<0.10.0,>=0.9.0, but you have typer 0.12.3 which is incompatible.\n",
      "langchain-anthropic 0.1.11 requires langchain-core<0.2.0,>=0.1.43, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-aws 0.1.3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-community 0.2.17 requires langchain<0.3.0,>=0.2.16, but you have langchain 0.3.0 which is incompatible.\n",
      "langchain-community 0.2.17 requires langchain-core<0.3.0,>=0.2.39, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-experimental 0.0.53 requires langchain<0.2.0,>=0.1.8, but you have langchain 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.0.53 requires langchain-core<0.2.0,>=0.1.27, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-google-genai 1.0.3 requires langchain-core<0.2,>=0.1.45, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-groq 0.1.3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.3.5 which is incompatible.\n",
      "langchain-openai 0.1.6 requires langchain-core<0.2.0,>=0.1.46, but you have langchain-core 0.3.5 which is incompatible.\n",
      "llama-index 0.8.5.post2 requires langchain<=0.0.266,>=0.0.262, but you have langchain 0.3.0 which is incompatible.\n",
      "scrapegraphai 0.10.0 requires langchain==0.1.15, but you have langchain 0.3.0 which is incompatible.\n",
      "scrapegraphai 0.10.0 requires tiktoken<0.7.0,>=0.6.0, but you have tiktoken 0.7.0 which is incompatible.\n",
      "scrapegraphai 0.10.0 requires tqdm<5.0.0,>=4.66.4, but you have tqdm 4.66.1 which is incompatible.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "swiftrank 1.3.0 requires orjson==3.9.10, but you have orjson 3.10.5 which is incompatible.\n",
      "swiftrank 1.3.0 requires pydantic==2.6.4, but you have pydantic 2.9.2 which is incompatible.\n",
      "swiftrank 1.3.0 requires uvicorn==0.29.0, but you have uvicorn 0.25.0 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#@title Install and import necessary libraries\n",
    "%pip install -qU tool-parse[langchain] langchain-ollama langgraph duckduckgo-search\n",
    "\n",
    "from tool_parse.integrations.langchain import ExtendedStructuredTool, patch_chat_model\n",
    "\n",
    "import typing as t\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtendedStructuredTool(name='search_text', description='Search for text in the web.', func=<function search_text at 0x000001840CC5F910>),\n",
       " ExtendedStructuredTool(name='product_info', description='Information about the product.', func=<class '__main__.ProductInfo'>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def search_text(\n",
    "    text: str,\n",
    "    *,\n",
    "    safe_search: bool = True,\n",
    "    backend: t.Literal[\"api\", \"html\", \"lite\"] = \"api\",\n",
    "    max_results: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for text in the web.\n",
    "    :param text: Text to search for.\n",
    "    :param safe_search: If True, enable safe search.\n",
    "    :param backend: Backend to use for retrieving results.\n",
    "    :param max_results: Max results to return.\n",
    "    \"\"\"\n",
    "    return DDGS().text(\n",
    "        keywords=text,\n",
    "        safesearch=\"on\" if safe_search else \"off\",\n",
    "        backend=backend,\n",
    "        max_results=max_results,\n",
    "    )\n",
    "\n",
    "class ProductInfo(t.NamedTuple):  # Can be t.TypedDict or pydantic.BaseModel\n",
    "    \"\"\"\n",
    "    Information about the product.\n",
    "    :param name: Name of the product.\n",
    "    :param price: Price of the product.\n",
    "    :param in_stock: If the product is in stock.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    price: float\n",
    "    in_stock: bool = False\n",
    "\n",
    "tools = [\n",
    "    ExtendedStructuredTool(func=search_text),\n",
    "    ExtendedStructuredTool(func=ProductInfo, name=\"product_info\"),\n",
    "]\n",
    "# OR # tools = ExtendedStructuredTool.from_objects(search_text, ProductInfo)\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patch the langchain chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = patch_chat_model(ChatOllama(model=\"llama3-groq-tool-use\")) # Patch the instance\n",
    "# OR\n",
    "model = patch_chat_model(ChatOllama)(model=\"llama3-groq-tool-use\") # Patch the class and then instantiate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=MemorySaver())\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "def query_agent(__query: str):\n",
    "    for chunk in agent_executor.stream({\"messages\": [HumanMessage(content=__query)]}, config):\n",
    "        message = list(chunk.values())[0][\"messages\"][0]\n",
    "        if isinstance(message, AIMessage):\n",
    "            print(\"[AGENT]\")\n",
    "            if message.tool_calls:\n",
    "                print(\"Calling tool:\")\n",
    "                metadata = message.tool_calls[0]\n",
    "                print(f\"name={metadata['name']!r}\")\n",
    "                print(f\"arguments={metadata['args']}\")\n",
    "            else:\n",
    "                print(message.content)\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"[{message.name!r} TOOL OUTPUT]\")\n",
    "            print(message.content)\n",
    "\n",
    "        print(\"---\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AGENT]\n",
      "Calling tool:\n",
      "name='search_text'\n",
      "arguments={'backend': 'lite', 'max_results': 5, 'text': 'langraph docs'}\n",
      "------------------------------------------------------------\n",
      "['search_text' TOOL OUTPUT]\n",
      "[{\"title\": \"LangGraph - LangChain\", \"href\": \"https://www.langchain.com/langgraph\", \"body\": \"LangGraph is a framework for building stateful, multi-actor agents with LLMs that can handle complex scenarios and collaborate with humans. LangGraph Cloud is a service for deploying and scaling LangGraph applications, with a built-in Studio for prototyping, debugging, and sharing.\"}, {\"title\": \"️LangGraph - GitHub Pages\", \"href\": \"https://langchain-ai.github.io/langgraph/\", \"body\": \"LangGraph is a framework for creating stateful, multi-actor applications with LLMs, inspired by Pregel and Apache Beam. It offers cycles, controllability, persistence, human-in-the-loop, and streaming features, and integrates with LangChain and LangSmith.\"}, {\"title\": \"langgraph/README.md at main · langchain-ai/langgraph - GitHub\", \"href\": \"https://github.com/langchain-ai/langgraph/blob/main/README.md\", \"body\": \"LangGraph is a Python framework that allows you to create stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. Learn how to use LangGraph with LangChain, LangSmith, and Anthropic tools to build agent and multi-agent workflows.\"}, {\"title\": \"️LangGraph.js - GitHub Pages\", \"href\": \"https://langchain-ai.github.io/langgraphjs/\", \"body\": \"LangGraph.js is a low-level framework that allows you to create stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. Learn how to define graph states, tools, and workflows with examples and integration with LangChain.\"}, {\"title\": \"Tutorials - GitHub Pages\", \"href\": \"https://langchain-ai.github.io/langgraph/tutorials/\", \"body\": \"Learn how to use LangGraph, a framework for building language agents as graphs, through various examples and scenarios. Explore chatbots, code assistants, multi-agent systems, planning agents, reflection agents, and more.\"}]\n",
      "------------------------------------------------------------\n",
      "[AGENT]\n",
      "I found 5 sources related to langraph docs:\n",
      "1. [LangGraph - LangChain](https://www.langchain.com/langgraph)\n",
      "2. [️LangGraph - GitHub Pages](https://langchain-ai.github.io/langgraph/)\n",
      "3. [langgraph/README.md at main · langchain-ai/langgraph - GitHub](https://github.com/langchain-ai/langgraph/blob/main/README.md)\n",
      "4. [️LangGraph.js - GitHub Pages](https://langchain-ai.github.io/langgraphjs/)\n",
      "5. [Tutorials - GitHub Pages](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Search 5 sources for langgraph docs using lite backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AGENT]\n",
      "Calling tool:\n",
      "name='product_info'\n",
      "arguments={'in_stock': True, 'name': 'RTX 4900', 'price': 3500}\n",
      "------------------------------------------------------------\n",
      "['product_info' TOOL OUTPUT]\n",
      "[\"RTX 4900\", 3500.0, true]\n",
      "------------------------------------------------------------\n",
      "[AGENT]\n",
      "The product RTX 4900 is priced at $3,500 and is currently in stock.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Parse the product: RTX 4900, priced at $3.5k, is in stock.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
